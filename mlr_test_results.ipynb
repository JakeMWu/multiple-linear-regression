{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354cd365-6e0f-4377-aab9-70c08b9cedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314af0eb-fead-404a-8619-34bb1a5bb6fa",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "We're going to use a small toy data set to apply what we've learnt about multiple linear regression. Each row is an observation of a student's test results for three term exams and their finals. We'll be using three features: Exams 1, 2, and 3 to try and predict the the student's finals test result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c12eacf-2c1f-472e-bae7-ac3d12bcd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXAM1</th>\n",
       "      <th>EXAM2</th>\n",
       "      <th>EXAM3</th>\n",
       "      <th>FINAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXAM1  EXAM2  EXAM3  FINAL\n",
       "0     73     80     75    152\n",
       "1     93     88     93    185\n",
       "2     89     91     90    180\n",
       "3     96     98    100    196\n",
       "4     73     66     70    142\n",
       "5     53     46     55    101\n",
       "6     69     74     77    149\n",
       "7     47     56     60    115\n",
       "8     87     79     90    175\n",
       "9     79     70     88    164"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"psych_test_results.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f39005-4749-4e79-b25b-830d8213e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.iloc[:,0:3])\n",
    "y = np.array(df.iloc[:,3])\n",
    "train_size = int(X.shape[0]*0.8)\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5514d0f1-6acf-4f26-b4bc-d666f46f9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking an 80:20 test:train split\n",
    "X_train = X[0:train_size,:]\n",
    "y_train = y[0:train_size]\n",
    "X_test = X[train_size:,:]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e12e7e-5464-40d7-b0e7-97f1dfef919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20, 3) and\n",
      "y_train shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape} and\\ny_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdd2d05-6ff4-4c56-9972-f552c4a38585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "b_init = 0\n",
    "w_init = np.zeros(3,)\n",
    "print(w_init.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca08cf2-4152-497c-80f3-c5a939157056",
   "metadata": {},
   "source": [
    "We're carefully keeping track of the shape of our data and ensuring that our model's weights (w) have the correct shape for the number of features. \n",
    "\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5f29c6-41c7-495c-bda3-811307baba93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    \n",
    "    computes cost of model\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters\n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0] # number of examples\n",
    "    cost = 0.0 # initializing cost\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b   # dot product of the ith example. A scalar\n",
    "        cost = cost + (f_wb_i - y[i])**2 # summing cost\n",
    "    cost = cost/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db7bb49-d2bd-4830-887b-228411c0f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes gradient for linear regression\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters\n",
    "      b (scalar)       : model parameter\n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar       : The gradient of the cost w.r.t. the parameter b\n",
    "    \"\"\"\n",
    "    m,n = X.shape #m examples, n features\n",
    "    # initialize gradient w.r.t paremeters \n",
    "    dj_dw = np.zeros((n,)) # vector (array) of zeros of size n\n",
    "    dj_db = 0.0\n",
    "    \n",
    "    for i in range(m):\n",
    "        err = (np.dot(X[i], w) + b) - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
    "        dj_db = dj_db + err\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    return dj_db, dj_dw    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0c9ca2-5118-408d-a6f4-2814def8d6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))  : Data, m examples with n features\n",
    "      y (ndarray (m,))   : target values \n",
    "      w_in (ndarray (n,)): initial model parameters\n",
    "      b_in(scalar)       : initial model paramter\n",
    "      cost_function      : function to compute cost\n",
    "      gradient_function  : function to compute gradient\n",
    "      alpha (float)      : learning rate\n",
    "      num_iters (int)    : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : updated values of parameters \n",
    "      b (scalar)       : updated value of parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        dj_db, dj_dw = gradient_function(X, y, w, b)\n",
    "        \n",
    "        # update parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633ff855-cb4f-451f-b41f-8165a26d6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for parameters w and b initialized at 0: 12966.375\n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'cost for parameters w and b initialized at 0: {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1717aec2-3b19-4a03-a213-5777c471a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrying out multiple linear regression via gradient descent\n",
    "alpha = 0.0001  # step size\n",
    "w, b = gradient_descent(X_train, y_train, w_init, b_init, compute_cost, compute_gradient, alpha, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8672c1b2-567d-4bf0-a442-6a5524811725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For our model, the parameters w are [0.43461029 0.52320506 1.05281377] and b is -0.049\n"
     ]
    }
   ],
   "source": [
    "print(f\"For our model, the parameters w are {w} and b is {round(b, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefb6490-2e23-49ce-988b-6caa0f10e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.977\n"
     ]
    }
   ],
   "source": [
    "test_cost = math.sqrt(compute_cost(X_test, y_test, w, b)*2) # rms error\n",
    "print(round(test_cost, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbc64352-3a6f-4b4f-b954-623388592f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predicted value for observation 21 is: 175.3 with actual value 177\n",
      "Our predicted value for observation 22 is: 173.9 with actual value 175\n",
      "Our predicted value for observation 23 is: 166.8 with actual value 175\n",
      "Our predicted value for observation 24 is: 151.2 with actual value 149\n",
      "Our predicted value for observation 25 is: 190.3 with actual value 192\n"
     ]
    }
   ],
   "source": [
    "# Performance of our model against the test set. This isn't rigorous\n",
    "our_predictions = np.zeros(5,)\n",
    "for i in range(X_test.shape[0]):\n",
    "    y = np.dot(w, X_test[0 + i]) + b\n",
    "    our_predictions[i] = y\n",
    "    print(f\"Our predicted value for observation {21+i} is: {round(y, 1)} with actual value {y_test[0 + i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891308c-72b7-425d-88be-fc667d04f8ec",
   "metadata": {},
   "source": [
    "### Using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb522c4c-26d9-4ec6-a908-c0b75c6a4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "sk_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43572c10-9d25-4606-b16f-aa4dc0a83682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKlearns predicted value for observation 21 is: 175.6 with actual value 177\n",
      "SKlearns predicted value for observation 22 is: 174.2 with actual value 175\n",
      "SKlearns predicted value for observation 23 is: 166.9 with actual value 175\n",
      "SKlearns predicted value for observation 24 is: 150.8 with actual value 149\n",
      "SKlearns predicted value for observation 25 is: 190.8 with actual value 192\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    print(f\"SKlearns predicted value for observation {21+i} is: {round(sk_predictions[0+i], 1)} with actual value {y_test[0 + i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1783c1db-390e-4fec-b865-7539c4ac1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mse for our model: 15.818 vs sk's mse: 14.732\n"
     ]
    }
   ],
   "source": [
    "our_mse= mean_squared_error (y_test, our_predictions)\n",
    "sk_mse = mean_squared_error(y_test, sk_predictions)\n",
    "print(f\"The mse for our model: {round(our_mse,3)} vs sk's mse: {round(sk_mse,3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
