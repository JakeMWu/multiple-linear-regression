{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354cd365-6e0f-4377-aab9-70c08b9cedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314af0eb-fead-404a-8619-34bb1a5bb6fa",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "We're going to use a small data set to apply what we've learnt about multiple linear regression. Each row is an observation of a student's Psych test results for three term exams and their finals. We'll be using three features: Exams 1, 2, and 3 to try and the student's final exam result will be the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c12eacf-2c1f-472e-bae7-ac3d12bcd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXAM1</th>\n",
       "      <th>EXAM2</th>\n",
       "      <th>EXAM3</th>\n",
       "      <th>FINAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EXAM1  EXAM2  EXAM3  FINAL\n",
       "20     82     86     90    177\n",
       "21     86     82     89    175\n",
       "22     78     83     85    175\n",
       "23     76     83     71    149\n",
       "24     96     93     95    192"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"psych_test_results.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f39005-4749-4e79-b25b-830d8213e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.iloc[:,0:3])\n",
    "y = np.array(df.iloc[:,3])\n",
    "train_size = int(X.shape[0]*0.8)\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5514d0f1-6acf-4f26-b4bc-d666f46f9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking an 80:20 test:train split\n",
    "X_train = X[0:train_size,:]\n",
    "y_train = y[0:train_size]\n",
    "X_test = X[train_size:,:]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e12e7e-5464-40d7-b0e7-97f1dfef919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20, 3) and\n",
      "y_train shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape} and\\ny_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdd2d05-6ff4-4c56-9972-f552c4a38585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "b_init = 0\n",
    "w_init = np.zeros(3,)\n",
    "print(w_init.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca08cf2-4152-497c-80f3-c5a939157056",
   "metadata": {},
   "source": [
    "We're carefully keeping track of the shape of our data and ensuring that our model's weights (w) have the correct shape for the number of features. \n",
    "\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5f29c6-41c7-495c-bda3-811307baba93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    \n",
    "    computes cost of model\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters\n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0] # number of examples\n",
    "    cost = 0.0 # initializing cost\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b   # dot product of the ith example. A scalar\n",
    "        cost = cost + (f_wb_i - y[i])**2 # summing cost\n",
    "    cost = cost/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db7bb49-d2bd-4830-887b-228411c0f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes gradient for linear regression\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters\n",
    "      b (scalar)       : model parameter\n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar       : The gradient of the cost w.r.t. the parameter b\n",
    "    \"\"\"\n",
    "    m,n = X.shape #m examples, n features\n",
    "    # initialize gradient w.r.t paremeters \n",
    "    dj_dw = np.zeros((n,)) # vector (array) of zeros of size n\n",
    "    dj_db = 0.0\n",
    "    \n",
    "    for i in range(m):\n",
    "        err = (np.dot(X[i], w) + b) - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
    "        dj_db = dj_db + err\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    return dj_db, dj_dw    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0c9ca2-5118-408d-a6f4-2814def8d6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))  : Data, m examples with n features\n",
    "      y (ndarray (m,))   : target values \n",
    "      w_in (ndarray (n,)): initial model parameters\n",
    "      b_in(scalar)       : initial model paramter\n",
    "      cost_function      : function to compute cost\n",
    "      gradient_function  : function to compute gradient\n",
    "      alpha (float)      : learning rate\n",
    "      num_iters (int)    : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : updated values of parameters \n",
    "      b (scalar)       : updated value of parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w_in) # Avoid altering w_in\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        dj_db, dj_dw = gradient_function(X, y, w, b) # this stores the respective gradients so we can update w and b simultaneously i.e. \n",
    "        \n",
    "        # update parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db # dj_db isn't altered by the new w value\n",
    "        \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633ff855-cb4f-451f-b41f-8165a26d6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for parameters w and b initialized at 0: 12966.375\n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'cost for parameters w and b initialized at 0: {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1717aec2-3b19-4a03-a213-5777c471a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrying out multiple linear regression via gradient descent\n",
    "alpha = 0.0001  # step size\n",
    "w, b = gradient_descent(X_train, y_train, w_init, b_init, compute_cost, compute_gradient, alpha, 10000)\n",
    "print(f\"For our model, the parameters w are {w} and b is {round(b, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aefb6490-2e23-49ce-988b-6caa0f10e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model has a root mean squared error of 3.974 against the test data set\n"
     ]
    }
   ],
   "source": [
    "test_cost = math.sqrt(compute_cost(X_test, y_test, w, b)*2) # rms error\n",
    "print(f\"Our model has a root mean squared error of {round(test_cost, 3)} against the test data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbc64352-3a6f-4b4f-b954-623388592f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predicted value for observation 21 is: 175.3 with actual value 177\n",
      "Our predicted value for observation 22 is: 173.9 with actual value 175\n",
      "Our predicted value for observation 23 is: 166.8 with actual value 175\n",
      "Our predicted value for observation 24 is: 151.1 with actual value 149\n",
      "Our predicted value for observation 25 is: 190.4 with actual value 192\n"
     ]
    }
   ],
   "source": [
    "# Performance of our model against the test set. Just something to eyeball\n",
    "our_predictions = np.zeros(5,)\n",
    "for i in range(X_test.shape[0]):\n",
    "    y = np.dot(w, X_test[0 + i]) + b\n",
    "    our_predictions[i] = y # storing our test prediction in an array\n",
    "    print(f\"Our predicted value for observation {21+i} is: {round(y, 1)} with actual value {y_test[0 + i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891308c-72b7-425d-88be-fc667d04f8ec",
   "metadata": {},
   "source": [
    "### Using Scikit-learn\n",
    "We'll implement a model using sk-learn just to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb522c4c-26d9-4ec6-a908-c0b75c6a4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "sk_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43572c10-9d25-4606-b16f-aa4dc0a83682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKlearns predicted value for observation 21 is: 175.6 with actual value 177\n",
      "SKlearns predicted value for observation 22 is: 174.2 with actual value 175\n",
      "SKlearns predicted value for observation 23 is: 166.9 with actual value 175\n",
      "SKlearns predicted value for observation 24 is: 150.8 with actual value 149\n",
      "SKlearns predicted value for observation 25 is: 190.8 with actual value 192\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    print(f\"SKlearns predicted value for observation {21+i} is: {round(sk_predictions[0+i], 1)} with actual value {y_test[0 + i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1783c1db-390e-4fec-b865-7539c4ac1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mse for our model: 15.818 vs sk's mse: 14.732\n"
     ]
    }
   ],
   "source": [
    "our_mse= mean_squared_error (y_test, our_predictions)\n",
    "sk_mse = mean_squared_error(y_test, sk_predictions)\n",
    "print(f\"The mse for our model: {round(our_mse,3)} vs sk's mse: {round(sk_mse,3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
